tokenizer_max_length: 5012
max_data_points: null # limit on amount of data for debug

adapter_checkpoint: "${path_after_train}/best" # null
batch_size: 4

use_vllm: False

defaults:
  - bits_and_bytes: codellama
  - generation: codellama
  - generation_vllm: codellama
  - prompt: codellama_recursive # /train/prompt@prompt: base_prompt
  - _self_
